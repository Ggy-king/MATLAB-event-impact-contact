clc
clear
A=[3565.31000000000,3153.14000000000,3126.46000000000,3065.31000000000;
    3147.91000000000,3153.14000000000,3145.50000000000,3154.28000000000;
    3148.53000000000,3153.14000000000,3153.14000000000,3157.74000000000;
    3153.14000000000,3163.78000000000,3172.03000000000,3153.03000000000;
     3146.69000000000,3153.14000000000,3167.03000000000,3136.27000000000;
    3153.14000000000,3165.57000000000,3173.58000000000,3157.33000000000;
    3165.79000000000,3100.10000000000,3153.14000000000,3230.11000000000;
    3153.14000000000,3123.60000000000,3144.97000000000,3115.97000000000]; 
x1=A(:,1)';   %%%%%sqrs表示输入自变量
x2=A(:,2)';   %%%%%sqrs表示输入自变量
x3=A(:,3)';   %%%%%sqrs表示输入自变量
x4=A(:,4)';   %%%%%sqrs表示输入自变量

 
 
y1=rand(32,8)
 
 
 
n=4 %%%%自变量的个数
m=32  %%%%因变量的个数
p=[x1;x2;x3;x4];  %将所有自变量合并得到输入数据矩阵
t=[y1]; %将所有因变量合并目标数据矩阵
%利用premnmx函数对数据进行归一化
 
[pn,minp,maxp,tn,mint,maxt]=premnmx(p,t); % 对于输入矩阵p和输出矩阵t进行归一化处理
u=ones(n,1);
dx=[-1*u,1*u];                   %归一化处理后最小值为-1，最大值为1
%BP网络训练
net=newff(dx,[n,7,m],{'tansig','tansig','purelin'},'traingdx'); %建立模型，并用梯度下降法训练．
 
net.trainParam.show=4000;               %1000轮回显示一次结果
net.trainParam.Lr=0.05;                 %学习速度为0.05
net.trainParam.epochs=40000;           %最大训练轮回为50000次
net.trainParam.goal=0.65*10^(-3);     %均方误差
net=train(net,pn,tn);                   %开始训练，其中pn,tn分别为输入输出样本
%利用原始数据对BP网络仿真
an=sim(net,pn);           %用训练好的模型进行仿真
a=postmnmx(an,mint,maxt); % 把仿真得到的数据还原为原始的数量级；
pnew=[x1
     x2
     x3
     x4
     ];   %%输入自变量的参数，每一行表示一个自变量，列数表示预测的个数
 
pnewn=tramnmx(pnew,minp,maxp); %利用原始输入数据的归一化参数对新数据进行归一化；
anewn=sim(net,pnewn);            %利用归一化后的数据进行仿真；
anew=postmnmx(anewn,mint,maxt)  %把仿真得到的数据还原为原始的数量级；
h=abs(y1-anew)./y1
w=sum(h)/3
 
 
 
 


